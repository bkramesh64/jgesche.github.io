---
layout: splash
title: "Predictive Maintenance Part 3 - Echo State Networks"
excerpt:
mathjax: true
author_profile: false
categories: PHM EchoStateNetworks ESN RNN NeuralNetworks
header:
  teaser: /assets/images/Cover/ESN.png
published: false
---

Echo State Network
==================

This post is a general introduction to neural, recurrent
neural networks and Echo State Networks.The basic elements of neural networks, the architecture, and principles of the training process will be presented in section
[Neural Networks](#NeuralNetworks).
Based on these concepts I will discuss the working principles of
recurrent neural networks in section [Reccurent Neural Networks](#ReccurentNeuralNetworks).
Then, we will elaborate on the paradigm of
Reservoir Computing and Echo State Networks in section [Echo State Networks](#EchoStateNetworks).
A future post will be devoted to evolutionary
optimization algorithms which can be applied for the training process
of the Echo State Network.

<a name="NeuralNetworks"></a>

Neural Networks
===============

An Artificial Neural Network (ANN) is an information processing paradigm
that is modelled after a cerebral cortex. A mammalian cerebral cortex
contains 10-14 billion neurons whereas an ANN has just hundreds
or thousands of neurones. Figure 1
shows the similarities between a biological neurone and the mathematical
model. The dendrites of the neurone are equivalent to the inputs
$$b_1$$,$$x_1$$ and $$x_2$$. The first input to the neurone is the bias $$b_1$$
which is a fixed value. Input $$x_1$$ and $$x_2$$ are weighted with their
corresponding weights $$w_1$$ and $$w_2$$.

<div style="text-align:center">
<img src="/assets/images/PHM/neurons.jpg" alt="test image size" width="90%">
<figcaption>Fig. 1: Depiction of biological neuron (left) and a mathematical model of a
neuron(right)</figcaption>
</div>

The weights $$w_{ij}^k$$ are learnable and control the influence of inputs
on the neurone activation. The superscript $$k$$ refers to the layer in the
network. The subscript $$j$$ denoted the $$j^{th}$$ neurone in the
$$(k-1)^{th}$$ layer and $$i$$ denoted the $$i^{th}$$ in layer $$k$$. The
weighted input signals and the bias get summed up and are forwarded to
the activation function. The activation function applies a non-linearity
to the system which enables a neural network to compute non-linear
problems. The simplest activation function is the Heaviside step
function which outputs binary values. The two only possible states, in
this case, are the neurone is firing or not. Neurone with such an
activation function is called a perceptron. A network of perceptrons is
referred to as multi-layer-perceptron (MLP). However, the abrupt change
of the function value when the threshold is reached is not desirable.
Therefore a common choice for the activation function is the sigmoid
function $$\sigma$$ or Rectified Linear units (ReLU).

Activation functions
--------------------

In practice, different activation functions are employed. Most common functions are
the sigmoid, hyperbolic tangent and identity activation function.

<figure>
    <img src ="/assets/images/PHM/activation.jpg" width="90%" alt="Activation functions">
    <captions>Left: Sigmoid Activation, Middle: tanh, Activation Right: Identity Activation</captions>
</figure>



- **Sigmoid:**

  The sigmoid function is a commonly used activation function in machine learning. Unlike the perceptron, the sigmoid function is a
  smoothly varying function between 0 and 1. The sigmoid function is
  defined by:

    $$\begin{align}
        \sigma(z)=\dfrac{1}{1+e^{-z}}
        \tag{1}
        \end{align}$$

    An important characteristic of the sigmoid and other activation
    functions is that they squash the unbounded input to a limited
    output ranges. A rescaled version of the sigmoid function is the
    hyperbolic tangent $$\tanh$$, which is also a commonly chosen
    activation function. Both, sigmoid and $$\tanh$$ functions suffer from
    a problem called vanishing gradient where the gradient goes to zero
    during training for small or very large activation values. This
    behaviour can be problematic for feed forward networks and RNNs. A
    solution to that problem are $$\tanh$$ activation functions or network
    structures that specifically deal with that problem.


- **Hyperbolic tangent:**

    The hyperbolic tangent activation function is a rescaled sigmoid
    function. The $$\tanh$$ function has an output range between $$-1$$ and
    $$1$$. Like the sigmoid function, the $$\tanh$$ function saturates,
    however it is zero centered and saturates for large negative or
    positive values. For efficient network training, the input is usually
    normalized and the mean subtracted. This makes the $$\tanh$$ function
    less prone to saturation than the sigmoid function.

    $$\begin{align}
        \sigma(z)=\tanh(z)
        \tag{2}
        \end{align}$$

-   **Identity:**

    The identity or linear function is the simplest activation function
    and only maps the input back to itself. In a multi-layer network
    with nonlinear hidden activations, the identity activation function
    can be used in the output layer to construct a nonlinear regressor.

    $$\begin{align}
                \sigma(z)=z
                \tag{3}
        \end{align}$$

Neural Network architectures
----------------------------

Neurones in a network are connected a-cyclical and arranged in
distinct layers. First, we will a review a simple neural network with a
single hidden layer. The leftmost layer is the input layer and the
neurons in this layer are called input neurons. The rightmost layer is
called the output layer and the layers in between are the hidden layers.
Most networks are fully-connected which implies that two adjacent layers
$$\mathit{i}$$ and $$\mathit{j}$$ are fully pairwise connected. Neurones
within a single layer usually do not share a connection. Since the only
permitted direction of information flow is forward. This network type is
called feedforward neural network.


<div style="text-align:center">
<img src="/assets/images/PHM/ESN/ANN.pdf" alt="test image size" height="80%" width="80%">
<figcaption>Fig. 2: A neural network with N=2 layers.</figcaption>
</div>

An ANN can be interpreted as a function that maps from an input vector
to an output vector. The behavior of a network is controlled by setting
the weights $$w_{ij}$$. The total number of weights between two fully
connected layers with $$\mathit{i}$$ and $$\mathit{j}$$ units is
$$\mathit{ij}$$. Setting the correct weights for the networks is performed
during the training process.

Training process for ANN
------------------------

Training an ANN is the iterative process of finding a set of weights
$$w_{ij}$$ that reduce the output error value $$\delta^{(L)}=y-\hat{y}^L$$.
Here, $$y$$ is the correct output value and $$\hat{y}$$ is our prediction.
Most commonly a gradient based training method like backpropagation is
used for training. The training process consists of a forward and
backward pass. The forward pass calculates the output of the network
$$a^{(L)}$$, compares it with the desired output and calculates the error
$$\delta^{(L)}$$. The error is propagated in the backward pass through the
network to update the weights and biases of the individual units. These
steps are repeated until the error $$\delta^{(L)}$$ drops below a defined
threshold.

For the forward pass, we consider a network like it is depicted in figure
2 with $$I$$ input units $$x_i$$. Each unit in
the first hidden layer calculates a weighted sum of the input units.
These intermediate nodes $$a_j^{(L)}$$ are called activation units.

$$\begin{align}
a_h^{(L)} = \sum_{i=1}^l w_{ij}x_i
\tag{4}
\end{align}$$

The activation units serve as input to the activation function
$$\sigma_h$$ which yields the final activation of the unit h.

$$\begin{align}
x_h^{(L)} = \sigma \left( a_h^{(L)}\right)
\tag{5}
\end{align}$$

and for an output neurone we get

$$\begin{align}
\hat{y}_j^{(L)}=\sigma\left( a_h^{(L)}\right)
\tag{6}
\end{align}$$

For a cost-function, we will consider the squared loss function which
sums over the error of each element of the output layer. Here, the
squared loss function only serves as an example but it is generally a
good choice for regression problems. For more information on
cost-functions see [1].

$$\begin{align}
C = \dfrac{1}{2n} \sum_{j=1}^M \left(\delta^{(L)} \right) ^2
\tag{7}
\end{align}$$

To adjust the weights of the network we have to propagate the error
$$\delta$$ backward through our network. This is achieved by calculating
the derivative of the cost-function with respect to the weights $$w_{ij}$$
and the bias $$b_i$$. First, we apply the chain-rule to the partial
derivative of the cost function

$$\begin{align}
\dfrac{\partial C}{\partial w_{j}^k}=\dfrac{\partial C}{\partial a_j^k}\dfrac{\partial a_j^k}{\partial w_j^k}
\tag{8}
\end{align}$$

The first derivative is the change of the cost-function due to a change
of the activation of that weight. We can denote this term as:

$$\begin{align}
\delta_j^k = \dfrac{\partial C}{\partial a_j^k}
\tag{9}
\end{align}$$

Substituting equation 4 into the second derivative gives

$$\begin{align}
x_j^{k-1} = \dfrac{\partial a_j^k}{\partial w_j^k}
\tag{10}
\end{align}$$

Putting it together yields an expression for the partial derivative

$$\begin{align}
\dfrac{\partial C}{\partial w_{j}^k}=\delta_j^k x_j^{k-1}
\tag{11}
\end{align}$$

The error terms are definied as follows:

$$\begin{align}
\delta_1^m = g_o^{\prime}(a_1^m)\left(\hat{y_d}-y_d\right)
\tag{12}
\end{align}$$

$$\begin{align}
\delta_j^k = g^{\prime}(a_j^k)\sum_{l=1}^{r^{k+1}}w_{jl}^{k+1}\delta_l^{k+1}
\tag{13}
\end{align}$$

The weights are updated according to

$$\begin{align}
\bigtriangleup w_{ij}^k = -\alpha \dfrac{\partial C}{\partial w_{j}k}
\tag{14}
\end{align}$$

For in deepth derivations of those equations refer to [3].

<a name="ReccurentNeuralNetworks"></a>

Reccurent Neural Networks
-------------------------

Recurrent Neural Networks are built from the same "building-blocks" like feedforward neural networks. The major difference is the employed architecture which is not as restrictive as the architecture of FFNs. RNNs are not organized in layers and neurons have direct feedback loops as depicted in figure 3. This allows for a more powerful and versatile network, which is also a closer representation of the cerebral cortex than ANNs. A prerequisite for feedback loops is that the neurons fire with a delay and only for a limited duration. This necessary because the output of a neuron should not immediately affect its input. The internal state created by the feedback loop allows the network to exhibit a dynamic temporal behavior. This memory of previous inputs that persists in the network, which enables the network to learn sequences and perform temporal associations and predictions. However, the cyclical structure causes problems in the training process. In feedforward networks, the error derivative is calculated during backpropagation with respect to the weights in the corresponding layer and the weights in the previous layers. The cyclical structure in RNNS forces us to express the derivative of the error in terms of itself. A solution to that problem is a simple transformation. By unrolling the RNN in time we can transform the RNN into feedforward network-like structure. This allows us to apply the learning methods, which were introduced in section **Training of RNNs**, to RNNs.  The details of the RNN training process will be discussed in the next section
 Figure 3 is a depiction of an unrolled RNN. Unrolling means that we write out the network for the whole input sequence.  $$u_t$$ is the input, $$x_t$$ is the hidden state and $$\hat{y}_t$$ is the prediction at timestep $$t$$. The activation at timestep $$t$$ can be expressed as:

$$\begin{align}
	x_t = \sigma\left( W_{HU} \cdot u(t) + W_{HH}  \cdot x(t-1)\right)
  \tag{15}
\end{align}$$
$$\begin{align}
		\hat{y}_t = \sigma \left( W_{HO}  \cdot x(t)\right)
    \tag{16}
\end{align}$$

The hidden state $$x_t$$ is a function of the current input $$u_t$$ and the previous hidden state $$x_{t-1}$$. Thus, the hidden state is the "memory" of the network. As an activation function $$\sigma$$ usually  $$\tanh$$ or ReLu is used. The parameters $HU,HO$ and $HH$  are stored in the weight  matrices $$W$$ and they are the same for layer.  

<div style="text-align:center">
<img src="/assets/images/PHM/RNN_unrolled.pdf" alt="test image size" height="80%" width="80%">
<figcaption>Fig. 3: Depiction of an RNN unrolled in time</figcaption>
</div>


Training of RNNs - Back Propagation Through Time
------------------------------------------------

One commonly used training algorithm for RNNs is back propagation through time (BPTT) which is an extension of the in section **Training process for ANN** introduced backpropagation algorithm. Other gradient descent based learning techniques are Forward Propagation or Real Time, Recurrent Learning, Fast Forward Propagation. \\
Assuming we have an RNN as depicted in figure 3 with input vectors $u$, output vectors $$\hat{y}$$ and the weight matrices $$W_{IH}$$, $$W_{HH}$$ and $$W_{HO}$$.
The forward activations and the error at the network output will be computed just as in the regular backpropagation algorithm. We will consider linear RNN in the following explanation.
The cost function at a timestep $$t$$ is given by the cross-entropy loss as :

$$\begin{align}
	C_t = -y_t \log \hat{y}_t
  \tag{17}
\end{align}$$

For the unrolled network the total error is the sum over the error at each time step.

$$\begin{align}
C = -\sum_t y_t \log \hat{y}_t
\tag{18}
\end{align}$$

In the backward pass we want to calculate the error derivatives with respect to the parameters HU,HH and HO. The derivatives are given by the sum of the parameters gradients:

$$\begin{align}
\dfrac{\partial C}{\partial W_{HO}} = \sum_{k=0}^n \dfrac{\partial C}{\partial x_k}u_k
\tag{19}
\end{align}$$


The derivative $$\dfrac{\partial C}{\partial W_{HO}}$$ is merely a function of $$y$$, $$\hat{y}$$ and HO at the current time step. However, the derivative $$\dfrac{\partial C}{\partial W_{HH}}$$ is more complex, since it is a  function of $$W_{HH}$$. For the partial derivative we write


$$\begin{align}
\dfrac{\partial C}{\partial x_k} = \sum_{k=0}^n \dfrac{\partial C}{\partial x_k}x_{k-1}
\tag{20}
\end{align}$$

which is also used in every previous timestep. As a consequence we have to backpropagate the error gradient from the current time step back to $t=0$.
The challenge of training RNN is caused by instabilities in their gradients.

$$\begin{align}
\dfrac{\partial C}{\partial x_{k-m}}= \prod_{t\geq i\geq k} \dfrac{\partial x_i}{\partial x_{i-1}}= \prod_{t\geq i\geq k} \textbf{W}_{HH}^T diag(\sigma'(x_{i-1}))
\tag{21}
\end{align}$$


For the linear case we set the activation function $$\sigma$$ to identity. A spectral radius (SR) of the recurrent weight matrix $$W_{HH}$$ larger one is sufficient for long term components to exploded and for $$SR<1$$ to vanish. Long term refers to components for which $$k \gg t$$. Exploding gradients makes the network sensitive to weight changes and vanishing gradients prevent the network from learning long-term dependencies.



Reservoir Computing
-------------------

Training an RNN used to be an inherently difficult task. Slow convergence and difficulties that arise when using gradient descent based training methods like backpropagation through time limited the possible applications of RNNs. In the late nineties $$\textit{Reservoir Computing }$$ emerged as a new field. The basic idea behind $$\textit{Reservoir Computing}$$ (RC) can be summarized as follows: "...as long as an RNN possessed certain generic properties, supervised adaptation of all interconnection weights is not necessary, and only training a memoryless supervised readout from it is enough to obtain excellent performance in many tasks" [4]. This discovery made it possible to train networks with higher numbers of internal neurons. Reservoir computing has been employed in a number of different fields like neuroscience, robotics, and stock price forecasting. The two most prominent used architectures are Echo State networks and Liquid State machines which are both based on the aforementioned principle but were developed independently by Herbert Jaeger and his team \cite{Jaeger2001a} and by Wolfgang Maass \cite{NatschlaegerETAL:02}.  
A major problem associated with Reservoir Computing is the black-box-like nature of the Reservoir. The random initialization of the internal nodes with all other ESN parameters fixed results in tremendous variation of the network performance. To find an initialization that works well for a  particular task a trial and error based approach is usually used.


In the following section, we will consider an ESN with K input units, N hidden/internal units and L output units. Activations of the input units are denoted as $$u(n)$$, the hidden units as  $$a(n)$$ and the output units as $$y(n)$$. Input weights are stored in a $$K \times N$$ matrix $$W^{in}$$, internal weights in a N x N matrix $$W$$ and the output weights in a $$L \times (N + K + L)$$ matrix $$W^{out}$$.  The weights for the feedback loop from the output back to the internal units are stored in a $$N \times L$$ matrix $$W^{back}$$. Like in the definitions of the RNN architecture in the preceding section cyclic connections are allowed in the hidden layer and the output layer. Furthermore, connections between output units and straight from the input to the output are possible. Figure 4 shows the general topology of an ESN.
<a name="EchoStateNetworks"></a>
### Echo State Networks

In the following section, we will consider an ESN with K input units, N hidden/internal units and L output units. Activations of the input units are denoted as $$u(n)$$, the hidden units as  $$a(n)$$ and the output units as $$y(n)$$. Input weights are stored in a $$K \times N$$ matrix $$W^{in}$$, internal weights in a N x N matrix $$W$$ and the output weights in a $$L \times (N + K + L)$$ matrix $$W^{out}$$.  The weights for the feedback loop from the output back to the internal units are stored in a $$N \times L$$ matrix $$W^{back}$$. Like in the definitions of the RNN architecture in the preceding section cyclic connections are allowed in the hidden layer and the output layer. Furthermore, connections between output units and straight from the input to the output are possible. Figure 4 shows the general topology of an ESN.  

<div style="text-align:center">
<img src="/assets/images/PHM/ESN/ESN_topology.png" alt="test image size" width="90%">
<figcaption>Fig. 4: Structure of an Echo State Network</figcaption>
</div>


For a typical ESN with leaky integrated discreet time continues-value units the update equations for the network are:

$$\begin{eqnarray}
\tilde{x}(n)=tanh\left( \textbf{W}^{in}\left[ 1;\textbf{u}(n)\right] +\textbf{Wx}(n-1)\right)
\tag{22}
\label{eqn:ESN_state}
\end{eqnarray}$$

$$\begin{eqnarray}
x(n) =\left( 1- \alpha\right) \textbf{x}\left( n-1\right) + \alpha \tilde{x}(n)
\tag{23}
\end{eqnarray}$$

Here $$\tilde{x}(n)$$ are the reservoir activities and $$x(n)$$ are its respective updates at time step n. Note that in this section the input values are denoted as $$u(n)$$ and not as $$x(n)$$ like in the previous chapters. $$\alpha \in [0, 1]$$ is the leaking rate. If the $$\alpha$$ value is set to $$\alpha = 1$$ the network is run without the leaky integration. As an activation function, the $$\tanh$$ function is usually employed. Other activation functions are also possible.
The output layer is defined as

$$\begin{eqnarray}
y(n)=\textbf{W}^{out}\left[ 1,\textbf{u}(n),\textbf{x}(n)\right]
\tag{24}
\label{eqn:ESN_output}
\end{eqnarray}$$

where $$y(n)$$ is the output of the network, $$\textbf{u}(n)$$ the training input of the network and $$\textbf{W}^{out}$$ the output weight matrix.

### Echo State property

An underlying requirement for ESN to function is the so-called echo
state property (ESP), which demands that the effects of the initial
state vanish over time. The initial state is dependent on properties of
the state matrix $$\textbf{W}$$ and the input $$u(n)$$. To enforce the ESP
the spectral radius of $$\textbf{W}$$ is usually chosen to be smaller than
1 and used to scale the state matrix to unity. However, this neither a
necessary nor a sufficient condition to ensure the ESP. An in-depth
review of sufficient conditions of the ESP can be found in
[6].

### Generating the reservoir

The reservoir is a high-dimensional expansion of the input $$u(n)$$ and
serves as a memory of the input at the same time. Both characteristics
should provide a signal space $$x(n)$$ which has a sufficient complexity
so that the target $$y(n)$$ can be obtained from a linear combination of
$x(n)$. The Reservoir is characterized by $$\textbf{W}^{in}$$,$$\textbf{W}$$
and the leaking rate $$\alpha$$. The input and reservoir connection
matrices $$W^{in}$$ and $$W$$ are generated randomly. The defining
parameters of the ESN reservoir are the number of nodes N, sparsity,
non-zero elements, the spectral radius of $$\textbf{W}$$ and scaling of
$$\textbf{W}^{in}$$. The size of the reservoir N has a major influence on
the performance of the network. The bigger the signal space $$x(n)$$ the
higher is the probability that a linear combination can be found that
approximates the target $$y(n)$$. However, increasing $$N$$ leads to an
increase in computation time. Especially during the training process,
this needs to be considered. Lower boundary for the N can be estimated
from the number of independent real values that the network needs to
remember.


Parameters of the ESN
---------------------

In analogy to the hyper-parameters of ANNs we can tune a set of
parameters of the echo state network that characterize the architecture.
Parameters which are considered in the scope of this work are: size of
the reservoir N, spectral radius SR, connectivity C, input units scaling
IS, input units shift IF, output feedback OFB, output units scaling OS,
output units shift OF and the leaking rate $$\alpha$$. According to
[4] one should prioritize the reservoir size, the input
scaling, spectral radius and the leaking rate in the training process.
We will now elaborate on these parameters:

-   **Spectral radius**

    The spectral radius of the reservoir connection matrix $$\textbf{W}$$
    scales the width of the distribution of non-zero elements. In the
    training process the connection matrix is initially divided by the
    spectral radius $$\rho(\textbf{W})$$. The resulting matrix with unit
    spectral radius is then scaled with a spectral radius that is
    obtained during the training process. A SR $$\rho(\textbf{W})<1$$ is
    often used to ensure that the echo state property is not violated.
    However even for non-zero inputs the echo state property can hold
    for $$\rho(\textbf{W})>1$$. For tasks where long term history
    information are necessary we want to set greater $$\rho(\textbf{W})$$.
    Therefore a spectral radius much greater than one might be the
    optimal choice. For such a setting it is advisable to ensure that
    the echo state property holds or employ conditions which are more
    restrictive but ensure that the ESP holds as previously discussed.

-   **Input Scaling**

  Input scaling defines the range [-a,a] from which we sample the
    values for $$W^{in}$$. Usually, all columns are scaled together using
    one freely adjustable parameter $$a$$. To optimize the performance of
    the network the first column of $$W^{in}$$ can be scaled separately.
    The first column is equivalent to the bias input of the neurons in
    an ANN.

-   **Connectivity**

  Connectivity is another critical parameter for ESN tuning. It is
  defined as the number of non-zero weights of the total number of
  weights in the network. A Connectivity of $$C=0.4$$ the number of non
  zero weights in a network with $$N=100$$ units will be 40. For
  hyperbolic tangent activation, it is reported that the connectivity
  does not influence the output of the network [2].
  However, other researchers attribute significant influence on the
  networks performance to the connectivity parameter [5]. It
  is recommended to set the connectivity to small values to ensure
  sparsity.

-   **Leakage**

    The leaking rate depends on the temporal structure of the data and
    can be described as the speed of the reservoir update
    dynamics discretized in time. [4]. In essence, the
    leaking rate controls the amount of memory of the ESN.

References
----------

[1] BISHOP, Christopher M.: Pattern Recognition and Machine Learning (Information Science and Statis- tics). Secaucus, NJ, USA : Springer-Verlag New York, Inc., 2006. – ISBN 0387310738

[2] KORYAKIN, Danil ; LOHMANN, Johannes ; BUTZ, Martin V.: Balanced Echo State Networks. In: Neural Netw. 36 (2012), Dezember, 35–45. http://dx.doi.org/10.1016/j.neunet.2012.08.008. – DOI 10.1016/j.neunet.2012.08.008. – ISSN 0893–6080

[3] LECUN, Yann ; BOTTOU, Leon ; ORR, Genevieve B. ; MÜLLER, Klaus R.: Efficient BackProp. Berlin, Heidelberg : Springer Berlin Heidelberg, 1998. – ISBN 978–3–540–49430–0, 9–50

[4] LUKOSEVICIUS, Mantas: A Practical Guide to Applying Echo State Networks. 2012. – To appear in Neural Networks: Tricks of the Trade, Reloaded. G. Montavon, G. B. Orr, and K.-R. MÃijller

[5] ONG, Qingsong ; FENG, Zuren: Effects of Connectivity Structure of Complex Echo State Net- work on Its Prediction Performance for Nonlinear Time Series. In: Neurocomput. 73 (2010), Juni, Nr. 10-12, 2177–2185. http://dx.doi.org/10.1016/j.neucom.2010.01.015

[6] IZZET B., Yildiza ; HERBERT, Jaeger ; STEFAN J., Kiebela: Re-Visiting the Echo State Property. 2012 (state). – Forschungsbericht
