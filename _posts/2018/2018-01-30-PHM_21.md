---
layout: splash
title: "Predictive Maintenance Part 2.2 - Particle Filter and the Interacting Multiple Model Algorithm"
excerpt:
mathjax: true
author_profile: false
categories: PHM GaussianProcess ParticleFilter IMM
related: true
header:
  teaser: /assets/images/Cover/IMM.pdf
published: true

---


Gaussian Process with Particle Filter - Part 2
==============================================

In this second part on Gaussian Process Regression with Particle Filtering for
time series prediction we will discuss how the Particle Filter works and how we can combine it
with the IMM algorithm to improve its performance. The following two resources are great to get started with
and Kalman and Baysian Filters:


1. [Probabilistic-Programming-and-Bayesian-Methods-for-Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers).

2. [Kalman and Bayesian Filters in Python](http://nbviewer.jupyter.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb)

Like in the previous post on Gaussian Process regression,  we will implement the algorithms in Python after short theoretical discussion of the basic working principles of both algorithms.


Monte Carlo Methods and why we use the Particle Filter
------------------------------------------------------

For a lot of real world applications it is necessary to obtain unknown quantities from observations. Prior knowledge is often available which allows us to use Bayesian models. The prior distribution can be related through likelihood to the the measurements or observations. Bayes' theorem then gives us the posterior distribution from which we can infer the unknown quantity.

 New input data is usually feed to the system sequentially, accordingly  we have to update the posterior distribution in sequential fashion. For linear Gaussian models the update process for the sequential posterior distribution is the Kalman Filter.
An extension of the Kalman Fiter to nonlinear problems is the extended Kalman Filter (EKF). The EKF linearizes the model and current state through a first order linearization. For highly nonlinear models the EKF can become unstable. This problem is overcome by the UKF which uses a deterministic sampling approach, the so called unscented transformation.
An alternative approach are sequential Monte Carlo based techniques like the Particle Filter. The PF  can process highly non-linear data, however this comes at the cost of high computational requirements.

<div style="text-align:center">
<img src="/assets/images/PHM/Filter_comp_acc.pdf" alt="test image size" height="30%" width="30%">
<figcaption>Fig. 2: The figure depicts the accuracy and computational complexity of the EKF, UKF and PF [5]</figcaption>
</div>


The UKF is good compromise between computational effort and accuracy. Depending on the problem hypothesis  a Kalman filter or a PF might be more suitable. A detailed review of different Kalman filter frameworks can be found in [3]. For the task of RUL estimation we will choose PF due to its ability to output high accuracy results on non-linear datasets and datasets with unknown noise distribution.

Basic principles of Particle Filtering
--------------------------------------

Particle filters are a sample based implementation of bayesian filters.
The particle filter generates a set of random particles/samples where
each particle represents a possible current state of the system. Again
we assume a bayesian model and run the generated particles throughout
the model to get a posterior distribution. In this section the basic
particle filter algorithm, also know as sequential importance sampling
(SIS) will be introduced. Afterwards we will address a major shortcoming of the SIS and show a possible solution.

The prediction step passes each particle $$x_{n-1}$$ through the process
model $$f_n$$ and generates a set of prior samples
$$p\left( x_n \mid z_{1:n-1}\right)$$ for time step $$n$$. $$
x_n = f_n\left( x_{n-1},v_{n-1}\right)$$ Here $$v_{n-1}$$ denotes
the state noise vector. Since the state $$x_{n-1}$$ is usually not
observable we have to obtain information about the state from a noisy
measurement. The measurement process is described through function $$h_n$$
and to contribute for noisy measurements we have to add the noise term
$$k_n$$

$$\begin{align}
z_n = h_n\left( x_{n},k_{n}\right)
\tag{18}
\end{align}$$

In general a filtering problem is to obtain the estimation of the state
vector $$x_n$$ for time step $$n$$, if all the measurements before and at
time step n are provided. The first step for the computation of
$$p\left( x_n \mid z_{1:n-1}\right)$$ is the prediction step:

$$\begin{align}
p \left( x_n \mid \textbf{z}_{1:n-1}\right) = \int p\left( x_n \mid x_{n-1}\right) p\left( x_{n-1} \mid z_{1;n-1}\right) dx_{n-1}
\tag{19}
\label{eqn:PF_predict_analytic}
\end{align}$$

The distribution $$p \left( x_n \mid \textbf{z}_{1:n-1}\right)$$ is prior
over $$x_n$$ before we incorporate our knowledge of the measurement at
timestep $$n$$. In the update step we update our prior using the current
measurement at $$n$$.

$$\begin{align}
p \left( x_n \mid \textbf{z}_{1:n}\right) \propto p\left( z_n \mid x_{n}\right) p\left( x_{n} \mid z_{1:n-1}\right)
\tag{20}
\label{eqn:PF_update_analytic}\end{align}$$

The analytic equation for the prediction and update step can not easily
be computed. However, we can use Monte Carlo methods (MCM) to solve
those equations. The most basic MCM algorithm for this purpose is
sequential importance sampling(SIS). The main idea of SIS is to
approximate the posterior distribution
p$$\left( x_{0:n-1} \mid z_{0:n-1}\right)$$ with weighted particles. These
particles are continuously updated by feeding them to the state model to
approximate the posterior distribution for the next time step. It is not
possible to draw samples directly from a target distribution. A sample
from a proposal distribution is drawn instead. This method is called
importance sampling. To accommodate for the difference between the
target and proposal distribution we introduce a set of weights
$$w_i \propto \pi(x^{i}) / q(x^{i}) \text{with being proportional to p(x)}$$
which we use to adjust the draw samples $$x_i$$. Applying importance
sampling to our posterior distribution gives

$$\begin{align}
p \left( x_{n-1} \mid \textbf{z}_{1:n}\right) \approx \sum_{i=1}^N w_{n-1}^{i}\delta_{x_{n-1}^{i}}\left( x-x_i\right)
\tag{21}
\end{align}$$

where $$\delta_{x_{n-1}^{i}}$$ is a dirac delta function. Before we can
calculate the distribution
$$p \left( x_{n-1} \mid \textbf{z}_{1:n}\right)$$ we have to collect all
the data $$x_{1:n}$$. For every we new available measurement we also have
to recalculate the weights $$w$$, which increases the computational
complexity with every time step. However, it is possible to modify this
simple form of importance sampling so that it not necessary to modify
the past trajectory. We also assume that the proposal distribution only
depends on the most recent state and measurement
$$q\left( x_k^{i} \mid x_{0:k-1}^{i},z_{1:k}\right) = q\left( x_k^{i} \mid x_{k-1}^{i},z_{k}\right)$$.

$$\begin{align}
w_k^{i} \propto w_{k-1}^{i} \dfrac{p\left( z_k \mid x_k^{i}\right) p\left( x_k^{i} \mid x_{k-1}^{i}\right)  }{q\left( x_k^{i}\mid x_{k-1}^{i},z_{k}\right) }
\tag{22}
\end{align}$$


Weight Degeneracy and resampling
--------------------------------

A major shortcoming of the SIS is particle degeneration. Iterating over
the SIS update equations leaves only particles that match the
measurement with significant weights. Other particles are gradually
dominated by those particles with high weights. A common method to deal
with weight degeneracy is resampling. In resampling with replacement we
draw a new set of $$N$$ particles and replace the old set. Resampling can
be performed if the effective particle size drops below a threshold or
at every time step as in the Sampling Importance Resampling SIR
algorithm. The state and weight update equation simplify to :
$$\begin{align}
x_k^{i} \sim p\left( x_k \mid x_{k-1}^{i}\right)
\tag{23}
\label{eqn:SIR_update_state}
\end{align}$$
$$\begin{align}
w_k^{i} \propto p\left( z_k \mid x_{k}^{i}\right)
\tag{24}
\end{align}$$

Particle Filter for Multi Step Ahead Prediction
-----------------------------------------------

For prognostics it is necessary to extend the capabilities of the PF to
enable the projection of particles in time in the absence of
measurements. The simplest method as presented in [4] is a
simple continuation of the particle trajectories into the
future. Particle propagation starts at an initial state value estimate
$$\hat{x}_{t_p}^{i}$$.

$$\begin{align}
\hat{x}_{n+p}^{i} = E\left[ f_{f+p}\left( x_{t+p-1}^{i},w_{t+p}\right) \right]
\tag{25}
\end{align}$$

where $$f$$ is the state update model.By recursively applying the state
update equation the evolution in time of each particle can be estimated.
The PF requires the updating of particle weights to account for changing
process non-linearities and noise. In [4] two methods are
proposed for applying updating or resampling equations to the particle
weights. However, it is also possible to assume to particle weights to
be time invariant for the prediction process. According to
[4] this assumption yields satisfactory results for
prognostic applications. This due to the neglectable effect of the
particle weights on the prediction error compared to other error
sources. Therefore, particle weight updating was not implemented in the
p-step ahead PF algorithm.

Implementation of the Particle Filter
-------------------------------------

Lets assume we have know the degradation state $x^0$ of a considered system. First, we have to
generate particles that represent our belief about the current degradation state of our system.
We will create N particles and store them in a Nx1 shaped array.

```python
def gaussian_particles(mean,std,N):
  particles = np.empty((N,1)
  particles[:, 0] = mean + (randn(N) * std)
  return particles
```

## Prediction

Now we can use our state update model to update our belief in the system state.
The state update is given by equation 19 which represents our distribution
$$p\left( x_n \mid \textbf{z}_{1:n-1}\right)$$ is prior
over $$x_n$$ before we incorporate our knowledge of the measurement at
timestep $$n$$. The implementation of the state update for 1-dimensional system is
just a single line of code.


```python
def predict(particles, d, std, dt=1.):
    N = len(particles)
    degradation = (d[0] * dt) + (randn(N) * std[0])
```

## Update Step

In the next step we incorporate the next set of measurements to calculate our
posterior belief. We do that by assigning a prior probability to each particle
and multiply with the likelihood that the measurement matches the state.
The prior probability is calculated by assigning a weight to each particle and
then normalize these states. Normalization turns the weights into a probability
distribution

```python
def update(particles, weights, z, R):
  weights.fill(1.)
  mean = np.mean(particles[:, 0])
  weights *= stats.norm(mean, R).pdf(z)
  weights += 1.e-100
  weights /= sum(weights)
```

## SIR - Sequential Importance Resampling

As previously mentioned, the SIS as a major shortcoming - particle weights can
degenerate. Particles with very small weights do not represent the
probability distribution of the system or degradation state. By resampling we drop
those particles and replace them with particles with higher weights.
The simplest resampling algorithm uses random resampling.

 ```python
 def simple_resample(particles, weights):
     N = len(particles)
     cumulative_sum = np.cumsum(weights)
     cumulative_sum[-1] = 1.
     indexes = np.searchsorted(cumulative_sum, random(N))

     # resample according to indexes
     particles[:] = particles[indexes]
     weights.fill(1.0 / N)
 ```

 We do not want to resample at every time step, because we might not have new
 measurements. To impose a condition for resampling we are going to define
 a number of effective particles $$\hat{N}_{eff}$$ which make meaningful
 contribution to the probability distribution.   

 $$\hat{N}_{eff}$$ is defined as

 $$\begin{eqnarray}
\hat{N}_{eff}=\dfrac{1}{\sum w^2}
 \end{eqnarray}$$

```python
def neff(weights):
    return 1. / np.sum(np.square(weights))
```

If $$\hat{N}_{eff}$$ drops below a defined threshold we should resample our
particle weights.

# Putting it all together

Now we have defined all the necessary functions to implement the particle filter.
First we have create our particle distribution. Then we will call in a loop the
predict, update and resample functions.


```python
import numpy as np
from scipy import stats
from numpy.random import randn,random
import matplotlib.pyplot as plt


if __name__ == '__main__':
    N = 100 # Number of particles
    x_0 = 0.1 #initial state
    x_N = 0.001  # Noise covariance in the system
    x_R = 0.001  # Noise covariance in the measurement
    T = 10 # Time steps


    # Initial particles, gaussian distributed
    particles = gaussian_particles(x_0,x_N,N)

    weights = np.zeros(N)
    true_state = 0.1
    for t in range(T):

        d = 0.001 # State update model
        # measurement. We just add some random sensor noise
        true_state += 0.001


        z = true_state + (randn(N) * x_R)

        # predict particles
        predict(particles, d, x_N)

        # updated Observation
        z_updated = particles + (randn(N) * x_R)
        # incorporate measurements and update our belief- posterior
        update(particles, weights, z=z, R=x_R)

        # resample if number of effective particles drops below N/2
        if neff(weights) < N/2:

            simple_resample(particles, weights)


        mu, var = estimate(particles, weights)
```

The estimate() function in the last line returns the mean and variance of
the weighted particles.

```python
def estimate(particles, weights):
    mean = np.average(particles, weights=weights)
    var  = np.average((particles - mean)**2, weights=weights)
    return mean, var
```

Running the code will probably show relatively weak performance of
the particle filter. The reason is the simple_resample method which chooses
particles with low weights and therefore the particles represent the
 probability distribution of the system state rather poorly. A better resampling
 algorithm should select particles with higher probability, but also include some
 particles with lower probability to account for underlying unlinearities.

{% include /d3/particle_Filter_2.html %}




Interacting Multiple Model Approach
===================================

A prediction that is based just on one training data sets will not be
able to capture and adjust to dynamically changing degradation states.
The assumption is that by combining state predictions from multiple
models the overall performance of the prediction algorithm can be
improved. IMM filter are a well performing estimation algorithm for
Markov switching systems. Three major steps are performed by the filter:
interaction (mixing), filtering and combination. The initial condition
is obtained by mixing the state estimates and covariance produced by all
filters in the previous time steps. Next we use the mixed state values
to perform a single particle filtering step for each model. The state
updates and a current observation are then used to calculate the
likelihood of each filtering model. The likelihood combined with the
prior model probability and the state transition probabilities yield the
posterior model probabilities. In a last step the model probabilities
and the new state estimates are combined.


<div style="text-align:center">
<img src="/assets/images/PHM/IMM.pdf" alt="test image size" height="50%" width="50%">
<figcaption>Fig. 3: Blockdiagram of the IMM with two Particle Filters.</figcaption>
</div>

-   **State Mixing:** The initial condition is obtained by mixing the
    state estimates and the covariance produced by all filters in the
    previous time steps.The equation for the initial mixing step is
    given as

    $$\begin{align}
    x_{0j}= \sum_{i=1}^n x^{i}\mu_{ij}
    \tag{26}
    \label{eqn:IMM_mixedmean}\end{align}$$

    $$\begin{align}
    P_{0j}= \sum_{i=1}^n\mu_{ij}\left[ P^{i} + (x^{i}-x^{0j})\cdot(x^{i}-x^{0j})^T\right]
    \tag{27}
    \label{eqn:IMM_mixedvariance}\end{align}$$

    $$c^j$$ is the normalization vector and $$\bar{\mu}^{i\mid j}$$ the
    conditional model probabilities which are computed as follows:

    $$\begin{align}
    \bar{c}^j=\sum_{i=1}^{n}p^{ij}\mu_{k-1}^{i}
    \tag{28}
    \end{align}$$

    $$\begin{align}
    \bar{\mu}^{i\mid j}=\dfrac{1}{\bar{c}^j}p^{ij}\mu_{k-1}^{i}
    \tag{29}
    \end{align}$$

    Here $$p^{ij}$$ defines the probability of switching from model $$i$$ to
    model $$j$$.

-   **Model Proability:**

    In the next step we predict the mixed state estimate using the
    particle filter and the values from eqn 26 and 27 as inputs.
    We use results to calculate the likelihood of each model.

    $$\begin{align}
    \varLambda^j = \dfrac{1}{\sqrt{2 \pi}}\exp\left( -\dfrac{1}{2}\cdot Z_j^T \cdot S_j  \cdot Z_j\right)
    \tag{30}
    \label{eqn:IMM_likelihood}\end{align}$$

    where $$S_j$$ is the covariance of the observations and
    $$Z_j = m_0 - m^j$$. Here, $$m_0$$ is the observation for the given time
    step and $$m^j$$ is the predicted value for the filter model j. After
    calculating the likelihoods we can update the model probabilities.

    $$\begin{align}
    \mu^j=\dfrac{1}{c} \varLambda^j \bar{c}^j
    \tag{31}
    \label{eqn:IMM_probabilities}\end{align}$$

    where c is a normalization constant :

    $$\begin{align}
    c = \sum_{i=1}^n \varLambda^{i} {\bar{c}}^{i}
    \tag{32}
    \label{eqn:IMM_norm}\end{align}$$

-   **State Estimate Combination:**

    In a final step we can combine the state and covariance estimates.
    We sum over each model state and covariance $$P^{i}$$ weighted by the
    respective model probabilities $$\mu$$. For this step we make again
    use of equations 26 and 27.

    $$\begin{align}
    \textbf{X} = \sum_{i = 1}^N X^{i} \mu^{i}
    \tag{33}
    \label{eqn:IMM_updated state}\end{align}$$

    $$\begin{align}
    P = \sum_{i=1}^N \mu^{i}\left[ P^{i} + \left( X^{i} -X\right) \left( X^{i}-X\right) ^T\right]
    \tag{34}
    \label{eqn:IMM_updated_covariance}\end{align}$$

    References
    ----------
    [1] AVID, Kristjanson D.: Automatic Model Construction with Gaussian Processes, Diss., 2014

    [2] BISHOP, Christopher M.: Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA : Springer-Verlag New York, Inc., 2006. – ISBN 0387310738

    [3] CHEN, Zhe: Bayesian Filtering and From Kalman and Filters to and Particle Filters and Beyond, 2003

    [4] ORCHARD, Marcos E.: A Particle Filtering-based Framework for On-line Fault Diagnosis and Failure Prognosis, Diss., 2006

    [5] SIMON, D.: Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches. Wiley, 2006 https://books.google.de/books?id=UiMVoP_7TZkC. – ISBN 9780470045336
