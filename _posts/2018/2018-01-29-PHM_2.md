---
layout: splash
title: "Predictive Maintenance Part 2 - Gaussian Process Regression "
excerpt:
mathjax: true
author_profile: false
categories: PHM Gaussian Process Particle Filter
related: true
header:
  teaser: /assets/images/Cover/Gaussian.png
published: true
---


Gaussian Process with Particle Filter
=====================================

This post provides an introduction to the Gaussian Process and Particle Filtering
for time series prognosis. First we will discuss the working principles of the Gaussian Process. The GP can be introduced from a weight space or function space perspective. I will only consider the weight space approach. The weight space approach is more intuitive. Then, following an introduction to Monte Carlo Methods,  I will elaborate on the working principles of the Particle Filter. The last section presents the Interacting Multiple Model (IMM) approach. The IMM combines multiple particle filters with the aim of increasing prediction accuracy and robustness.

## Future Edit:
I will edit this post and add python code snippets over the next couple of days.

Gaussian Process
----------------

The Gaussian Process is a supervised learning method used for regression and classifications tasks. For future posts in this PHM series only the regression capabilities of the GP will be relevant.
The Gaussian Process defines a prior probability distribution over functions, without parametrizing the function $$f(u,w)$$ directly. Like a Gaussian distribution the GP is fully defined by its mean $$\mu$$ and covariance $$C\left( x,x'\right) $$. The mean $$\mu$$ is often assumed to be zero.

In the following section we will consider a training set $$\mathcal{D}$$ consisting of $$\mathit{n}$$ observations $$\mathcal{D} =\left\lbrace \left( x_i,y_i\right) \mid i = 1,...,n\right\rbrace $$. Here, $$\textbf{x}$$ is a $$\mathit{D}$$-dimensional input vector and $y$ is a noisy observation of the function $$$$. For simplicity we will assume that we model a linear model:
\begin{eqnarray}
y_i= f(\textbf{x}) + \epsilon = \textbf{x}^T \textbf{w} + \epsilon
\tag{1}
\end{eqnarray}

The additional noise $$\epsilon$$ of the function values shall be gaussian distributed with zero mean and variance $$\sigma^2$$. The vector $$\textbf{w}$$ is a parameter vector of the linear model

\begin{eqnarray}
\epsilon \sim \mathcal{N}\left( 0,\sigma_n^2\right)
\tag{2}
\end{eqnarray}


First we define a zero mean prior over the parameters of the model
\begin{eqnarray}
w \sim \mathcal{N}\left( 0,\Sigma\right)
\tag{3}
\end{eqnarray}

Given the observed values $$\textbf{y}$$ and the parameters $$\textbf{w}$$ we can calculate the likelihood of the observed values.

$$
\begin{eqnarray}
p\left( y \mid U ,\textbf{w}\right) = \prod_{i=1}^n p\left( y_i \mid u_i \textbf{w}\right) = \\
\prod_{i=1}^n \dfrac{1}{\sqrt{2 \pi}\sigma_n}\exp\left( -\dfrac{\left( y_i-u_i^Tw\right) ^2}{2 \sigma_n^2}\right) =\mathcal{N}\left( X^T \textbf{w},\sigma_n^2 I\right)
\tag{4}
\end{eqnarray}
$$

Bayes' theorem gives us the posterior distribution of $$\textbf{w}:$$


$$
\begin{eqnarray}
\text{posterior}= \dfrac{\text{likelihood x prior}}{\text{marginal likelihood}}
\tag{5}
\end{eqnarray}$$		



$$\begin{eqnarray}
p\left( \textbf{w} \mid y,X\right)  = \dfrac{p\left( y \mid X,\textbf{w}\right) p(\textbf{w})}{p\left( y \mid X\right) }
\tag{6}
\end{eqnarray}$$



The marginal likelihood, which normalizes the posterior distribution is given by
$$
\begin{eqnarray}
p\left( y \mid X\right) = \int p\left( y \mid X,\textbf{w}\right) p\left( \textbf{w}\right) d\textbf{w}
\tag{7}
\end{eqnarray}
$$
Plugging the terms for the likelihood, the prior and the marginal likelihood into equation 5 yields

$$\begin{eqnarray}
p\left( \textbf{w} \mid y,X\right)= \dfrac{p(y\mid X \textbf{w})p(\textbf{w})}{p(y \mid X)}=
\dfrac{\mathcal{N}_y\left( X^T \textbf{w},\sigma^2 I_n\right) \mathcal{N}_w\left( 0,\Sigma_p\right) }{\int \mathcal{N}_y\left( X^T \textbf{w},\sigma^2 I_n\right) \mathcal{N}_w\left( 0,\Sigma_p\right) d\textbf{w}}
\tag{8}
\end{eqnarray}$$


$$\begin{eqnarray}
\sim \mathcal{N}_y\left( X^T \textbf{w},\sigma^2 I_n\right) \mathcal{N}_w\left( 0,\Sigma_p\right)
\tag{9}
\end{eqnarray}$$


$$\begin{eqnarray}
= \exp \left( -\dfrac{1}{2}\left( w -\bar{w}\right) ^T\left( \dfrac{1}{\sigma^2}XX^T+\Sigma_p^{-1}\right) \left( w-\bar{w}\right) \right)
\tag{10}
\end{eqnarray}$$


where $$\bar{w} = \sigma^-2 \left(\dfrac{1}{\sigma^2}XX^T+\Sigma_p\right) ^{-1}Xy$$.

Using the abbreviation $$A=\dfrac{1}{\sigma^2}XX^T+\Sigma_p^{-1}$$ we can write the posterior as a Gaussian with mean $$\bar{w}$$ and covariance $$A^{-1}$$

$$\begin{eqnarray}
p\left( \textbf{w} \mid y,X\right)  &= \mathcal{N}_w\left(\bar{w},A^{-1} \right)
\tag{11}
\end{eqnarray}$$

Now our goal is to make predictions using the posterior 11 for new inputs $$x_{\ast}$$ from a test dataset given the training data.
For the predictive distribution $$f(x_\ast)$$  at $$x_\ast$$ we get an expression by averaging over all possible outputs of the linear model:

$$\begin{align}
p\left( f_\ast\mid x_\ast,y,X\right)  =\int p\left( f_*\mid x_*,\textbf{w}\right) p\left( \textbf{w}\mid y,X\right) d\textbf{w} = \mathcal{N}_{f_*}\left( x_*^T\bar{w},x_*^T A^{-1}
x_*\right)
\tag{12}
\end{align}$$



<div style="text-align:center">
<img src="/assets/images/PHM/GP_prior_posterior.pdf" alt="test image size" height="80%" width="80%">
<figcaption>Top left: A GP not conditioned on any data points. The gray shaded area depicts the covariance. Remaining plots: The posterior after conditioning on increasing amount of data points. All plots have the same axes.</figcaption>
</div>



The preceding equations of this section are only valid for the considered linear case. To overcome this limitation we can project the D-dimensional input into higher N-dimensional feature space by applying a basis function $$\phi(x)$$. This allows us to apply the posterior for the linear model in the high dimensional space instead of applying it directly on the input. Substituting $$\phi(x)$$ for $$X$$ in equation 12 yields:

$$\begin{align}
p\left( f_\ast\mid x_\ast,y,\phi(x)\right)   \sim \mathcal{N}_{f_*}\left( \phi(x)_*^T\bar{w},\phi(x)_*^T A^{-1}
\phi(x)_{*}\right)
\tag{13}
\label{eqn:posterior_ext}
\end{align}$$

with $$A=\dfrac{1}{\sigma_n^2}\phi(x)\phi(x)^T+\Sigma_p^{-1}$$. The NxN matrix needs to be inverted before we can use 13 for predictions. The computational complexity of an NxN matrix inversion is $$\mathcal{O}(n^3)$$. We can rewrite equation 13 which conveniently reduce computational overhead (Working directly with the basis function might be computationally faster for small datasets [2]).


$$\begin{align}
p\left( f_\ast\mid x_\ast,y,\phi(x)\right)   \sim \mathcal{N}\left( \phi_\ast\Sigma_p\Phi\left( K+\sigma_n^2 \textbf{I}\right) ^{-1}\textbf{y},\phi_\ast\ast\Sigma_p\phi_\ast-\phi_\ast^T\Sigma_{p}\Phi\left( K+\sigma_n^2 \textbf{I}\right) ^{-1}\Phi^T\Sigma_{p}\phi_\ast\right)
\tag{14}
\label{eqn:postior _feature_space}
\end{align}$$

In equation 14 we can find entries of form $$\phi_\ast\Sigma_p\Phi$$,$$\phi_\ast^T\Sigma_p\Phi$$ and $$\phi_\ast^T\Sigma_p\Phi_\ast$$. Thus, we can define $$k(x,x')=\phi(x)^T\Sigma_p\Phi(x')$$. $$k(\cot,\cot)$$ is called a covariance matrix or kernel. The kernel or covariance function has a considerable influence on the generalization properties of the GP. A short overview of different kernels will be provided later in this chapter. Usually the kernel has to be chosen although methods for automatic kernel selection have recently been developed [1].

Using the kernel notation we can write the equations for the mean and covariance  of the GPs posterior:

$$\begin{align}
\mathcal{GP}_{\mu}\left( f_\ast\mid X,y,X_\ast \right)  = k(x,x_\ast)\left[ k(x,x)+\sigma_n^2I\right] ^{-1}y
\tag{15}
\label{eqn:GP_pred_out}
\end{align}$$
$$\begin{align}
\mathcal{GP}_{\Sigma}\left( f_\ast\mid X,y,X_\ast \right)  = k\left(x_\ast,x_\ast\right)  - k\left( x_\ast,x\right) \left[ k(x,x)
+\sigma_n^2 I\right]  ^{-1}k(x,x_\ast)
\tag{16}
\label{eqn:GP_pred_cov}
\end{align}$$

where $$K = K(X,X)$$,$$K_\ast=K(X,X_\ast)$$ and for a single test point $$x_\ast$$ $$k(x_\ast)=k_\ast$$.


Kernels
-------

Kernels for Gaussian process models define the prior covariance between two points $$x$$ and $$x'$$.
Kernel functions $$k(\cdot,\cdot)$$ must meet certain requirements to ensure that they are valid kernels. A kernel k is valid if  the matrix K is positive semi-definite for any set of input values $$x_1,...x_n \in X$$. This guarantees that a mapping $$k(x,x')=\phi(x)^T\Sigma_p\Phi(x')$$. $$k(\cdot,\cdot)$$  does exist.
The choice of the right kernel has a large impact on the performance of the model, since it specifies which functions are likely under the GP prior [1].
Kernels are commonly constructed by combining basic kernels like linear, periodic or squared-exponential kernels. Combining basic kernels ensures that the resulting kernel is positive semi-definte. Constructing kernels from scratch is a more involved process, since it requires proving that matrix K is positive semi-definite. Figure 2 gives an intuition on how the employed kernel affects the respective model. The left plot in Figure 2  was generated using a Gaussian Process with a exponential kernel. For the right plot a squared-exponential kernel was used.


<div style="text-align:center">
<img src="/assets/images/PHM/kernel.pdf" alt="test image size" height="80%" width="80%">
<figcaption>Fig. 2: Left Plot: GP with a exponential kernel. Right Plot:  GP with a squared exponential kernel.</figcaption>
</div>

The squared-exponential kernel is a common kernel which performs well on a lot of problems. This kernel was also used throughout this thesis. The SE-kernel is defined as follows:

$$
\begin{align}
k(x,x')=\sigma_f^2 \exp\left( -\dfrac{(x-x')^2}{2l^2}\right)
\tag{17}
\end{align}$$

The parameters of a kernel are referred to as hyper-parameters. They are not parameters that specifically define a modelled function but a distribution over the function parameters. The hyper-parameters of the SE kernel are the length scale $$l$$, which defines how far the model can extrapolate from the data points. The variance $$\sigma_f^2$$ is merely a scaling factor and determines the average distance from the functions mean.


Monte Carlo Methods
-------------------

For a lot of real world applications it is necessary to obtain unknown quantities from observations. Prior knowledge is often available which allows us to use Bayesian models. The prior distribution can be related through likelihood to the the measurements or observations. Bayes' theorem then gives us the posterior distribution from which we can infer the unknown quantity.

 New input data is usually feed to the system sequentially, accordingly  we have to update the posterior distribution in sequential fashion. For linear Gaussian models the update process for the sequential posterior distribution is the Kalman Filter.
An extension of the Kalman Fiter to nonlinear problems is the extended Kalman Filter (EKF). The EKF linearizes the model and current state through a first order linearization. For highly nonlinear models the EKF can become unstable. This problem is overcome by the UKF which uses a deterministic sampling approach, the so called unscented transformation.
An alternative approach are sequential Monte Carlo based techniques like the Particle Filter. The PF  can process highly non-linear data, however this comes at the cost of high computational requirements.

<div style="text-align:center">
<img src="/assets/images/PHM/Filter_comp_acc.pdf" alt="test image size" height="30%" width="30%">
<figcaption>Fig. 2: The figure depicts the accuracy and computational complexity of the EKF, UKF and PF [5]</figcaption>
</div>


The UKF is good compromise between computational effort and accuracy. Depending on the problem hypothesis  a Kalman filter or a PF might be more suitable. A detailed review of different Kalman filter frameworks can be found in [3]. For the task of RUL estimation the PF was chosen due to its ability to output high accuracy results on non-linear datasets and datasets with unknown noise distribution.

Basic principles of Particle Filtering
--------------------------------------

Particle filters are a sample based implementation of bayesian filters.
The particle filter generates a set of random particles/samples where
each particle represents a possible current state of the system. Again
we assume a bayesian model and run the generated particles throughout
the model to get a posterior distribution. In this section the basic
particle filter algorithm, also know as sequential importance sampling
(SIS) will be introduced. Then a major shortcoming of the SIS will be
addressed and solution will be presented.

The prediction step passes each particle $$x_{n-1}$$ through the process
model $$f_n$$ and generates a set of prior samples
$$p\left( x_n \mid z_{1:n-1}\right)$$ for time step $$n$$. $$
x_n = f_n\left( x_{n-1},v_{n-1}\right)$$ Here $$v_{n-1}$$ denotes
the state noise vector. Since the state $$x_{n-1}$$ is usually not
observable we have to obtain information about the state from a noisy
measurement. The measurement process is described through function $$h_n$$
and to contribute for noisy measurements we have to add the noise term
$$k_n$$

$$\begin{align}
z_n = h_n\left( x_{n},k_{n}\right)
\tag{18}
\end{align}$$

In general a filtering problem is to obtain the estimation of the state
vector $$x_n$$ for time step $$n$$, if all the measurements before and at
time step n are provided. The first step for the computation of
$$p\left( x_n \mid z_{1:n-1}\right)$$ is the prediction step:

$$\begin{align}
p \left( x_n \mid \textbf{z}_{1:n-1}\right) = \int p\left( x_n \mid x_{n-1}\right) p\left( x_{n-1} \mid z_{1;n-1}\right) dx_{n-1}
\tag{19}
\label{eqn:PF_predict_analytic}
\end{align}$$

The distribution $$p \left( x_n \mid \textbf{z}_{1:n-1}\right)$$ is prior
over $$x_n$$ before we incorporate our knowledge of the measurement at
tilmestep $$n$$. In the update step we update our prior using the current
measurement at $$n$$.

$$\begin{align}
p \left( x_n \mid \textbf{z}_{1:n}\right) \propto p\left( z_n \mid x_{n}\right) p\left( x_{n} \mid z_{1:n-1}\right)
\tag{20}
\label{eqn:PF_update_analytic}\end{align}$$

The analytic equation for the prediction and update step can not easily
be computed. However, we can use Monte Carlo methods (MCM) to solve
those equations. The most basic MCM algorithm for this purpose is
sequential importance sampling(SIS). The main idea of SIS is to
approximate the posterior distribution
p$$\left( x_{0:n-1} \mid z_{0:n-1}\right)$$ with weighted particles. These
particles are continuously updated by feeding them to the state model to
approximate the posterior distribution for the next time step. It is not
possible to draw samples directly from a target distribution. A sample
from a proposal distribution is drawn instead. This method is called
importance sampling. To accommodate for the difference between the
target and proposal distribution we introduce a set of weights
$$w_i \propto \pi(x^{i}) / q(x^{i}) \text{with being proportional to p(x)}$$
which we use to adjust the draw samples $$x_i$$. Applying importance
sampling to our posterior distribution gives

$$\begin{align}
p \left( x_{n-1} \mid \textbf{z}_{1:n}\right) \approx \sum_{i=1}^N w_{n-1}^{i}\delta_{x_{n-1}^{i}}\left( x-xi\right)
\tag{21}
\end{align}$$

where $$\delta_{x_{n-1}^{i}}$$ is a dirac delta function. Before we can
calculate the distribution
$$p \left( x_{n-1} \mid \textbf{z}_{1:n}\right)$$ we have to collect all
the data $$x_{1:n}$$. For every we new available measurement we also have
to recalculate the weights $$w$$, which increases the computational
complexity with every time step. However, it is possible to modify this
simple form of importance sampling so that it not necessary to modify
the past trajectory. We also assume that the proposal distribution only
depends on the most recent state and measurement
$$q\left( x_k^{i} \mid x_{0:k-1}^{i},z_{1:k}\right) = q\left( x_k^{i} \mid x_{k-1}^{i},z_{k}\right)$$.

$$\begin{align}
w_k^{i} \propto w_{k-1}^{i} \dfrac{p\left( z_k \mid x_k^{i}\right) p\left( x_k^{i} \mid x_{k-1}^{i}\right)  }{q\left( x_k^{i}\mid x_{k-1}^{i},z_{k}\right) }
\tag{22}
\end{align}$$


Weight Degeneracy and resampling
--------------------------------

A major shortcoming of the SIS is particle degeneration. Iterating over
the SIS update equations leaves only particles that match the
measurement with significant weights. Other particles are gradually
dominated by those particles with high weights. A common method to deal
with weight degeneracy is resampling. In resampling with replacement we
draw a new set of $$N$$ particles and replace the old set. Resampling can
be performed if the effective particle size drops below a threshold or
at every time step as in the Sampling Importance Resampling SIR
algorithm. The state and weight update equation simplify to :
$$\begin{align}
x_k^{i} \sim p\left( x_k \mid x_{k-1}^{i}\right)
\tag{23}
\label{eqn:SIR_update_state}
\end{align}$$
$$\begin{align}
w_k^{i} \propto p\left( z_k \mid x_{k}^{i}\right)
\tag{24}
\end{align}$$

Particle Filter for Multi Step Ahead Prediction
-----------------------------------------------

For prognostics it is necessary to extend the capabilities of the PF to
enable the projection of particles in time in the absence of
measurements. The simplest method as presented in [4] is a
simple continuation of the particle trajectories into the
future. Particle propagation starts at an initial state value estimate
$$\hat{x}_{t_p}^{i}$$.

$$\begin{align}
\hat{x}_{n+p}^{i} = E\left[ f_{f+p}\left( x_{t+p-1}^{i},w_{t+p}\right) \right]
\tag{25}
\end{align}$$

where $$f$$ is the state update model.By recursively applying the state
update equation the evolution in time of each particle can be estimated.
The PF requires the updating of particle weights to account for changing
process non-linearities and noise. In [4] two methods are
proposed for applying updating or resampling equations to the particle
weights. However, it is also possible to assume to particle weights to
be time invariant for the prediction process. According to
[4] this assumption yields satisfactory results for
prognostic applications. This due to the neglectable effect of the
particle weights on the prediction error compared to other error
sources. Therefore, particle weight updating was not implemented in the
p-step ahead PF algorithm.


Interacting Multiple Model Approach
===================================

A prediction that is based just on one training data sets will not be
able to capture and adjust to dynamically changing degradation states.
The assumption is that by combining state predictions from multiple
models the overall performance of the prediction algorithm can be
improved. IMM filter are a well performing estimation algorithm for
Markov switching systems. Three major steps are performed by the filter:
interaction (mixing), filtering and combination. The initial condition
is obtained by mixing the state estimates and covariance produced by all
filters in the previous time steps. Next we use the mixed state values
to perform a single particle filtering step for each model. The state
updates and a current observation are then used to calculate the
likelihood of each filtering model. The likelihood combined with the
prior model probability and the state transition probabilities yield the
posterior model probabilities. In a last step the model probabilities
and the new state estimates are combined.


<div style="text-align:center">
<img src="/assets/images/PHM/IMM.pdf" alt="test image size" height="50%" width="50%">
<figcaption>Fig. 3: Blockdiagram of the IMM with two Particle Filters.</figcaption>
</div>

-   **State Mixing:** The initial condition is obtained by mixing the
    state estimates and the covariance produced by all filters in the
    previous time steps.The equation for the initial mixing step is
    given as

    $$\begin{align}
    x_{0j}= \sum_{i=1}^n x^{i}\mu_{ij}
    \tag{26}
    \label{eqn:IMM_mixedmean}\end{align}$$

    $$\begin{align}
    P_{0j}= \sum_{i=1}^n\mu_{ij}\left[ P^{i} + (x^{i}-x^{0j})\cdot(x^{i}-x^{0j})^T\right]
    \tag{27}
    \label{eqn:IMM_mixedvariance}\end{align}$$

    $$c^j$$ is the normalization vector and $$\bar{\mu}^{i\mid j}$$ the
    conditional model probabilities which are computed as follows:

    $$\begin{align}
    \bar{c}^j=\sum_{i=1}^{n}p^{ij}\mu_{k-1}^{i}
    \tag{28}
    \end{align}$$

    $$\begin{align}
    \bar{\mu}^{i\mid j}=\dfrac{1}{\bar{c}^j}p^{ij}\mu_{k-1}^{i}
    \tag{29}
    \end{align}$$

    Here $$p^{ij}$$ defines the probability of switching from model $$i$$ to
    model $$j$$.

-   **Model Proability:**

    In the next step we predict the mixed state estimate using the
    particle filter and the values from eqn 26 and 27 as inputs.
    We use results to calculate the likelihood of each model.

    $$\begin{align}
    \varLambda^j = \dfrac{1}{\sqrt{2 \pi}}\exp\left( -\dfrac{1}{2}\cdot Z_j^T \cdot S_j  \cdot Z_j\right)
    \tag{30}
    \label{eqn:IMM_likelihood}\end{align}$$

    where $$S_j$$ is the covariance of the observations and
    $$Z_j = m_0 - m^j$$. Here, $$m_0$$ is the observation for the given time
    step and $$m^j$$ is the predicted value for the filter model j. After
    calculating the likelihoods we can update the model probabilities.

    $$\begin{align}
    \mu^j=\dfrac{1}{c} \varLambda^j \bar{c}^j
    \tag{31}
    \label{eqn:IMM_probabilities}\end{align}$$

    where c is a normalization constant :

    $$\begin{align}
    c = \sum_{i=1}^n \varLambda^{i} {\bar{c}}^{i}
    \tag{32}
    \label{eqn:IMM_norm}\end{align}$$

-   **State Estimate Combination:**

    In a final step we can combine the state and covariance estimates.
    We sum over each model state and covariance $$P^{i}$$ weighted by the
    respective model probabilities $$\mu$$. For this step we make again
    use of equations 26 and 27.

    $$\begin{align}
    \textbf{X} = \sum_{i = 1}^N X^{i} \mu^{i}
    \tag{33}
    \label{eqn:IMM_updated state}\end{align}$$

    $$\begin{align}
    P = \sum_{i=1}^N \mu^{i}\left[ P^{i} + \left( X^{i} -X\right) \left( X^{i}-X\right) ^T\right]
    \tag{34}
    \label{eqn:IMM_updated_covariance}\end{align}$$


References
----------
[1] AVID, Kristjanson D.: Automatic Model Construction with Gaussian Processes, Diss., 2014

[2] BISHOP, Christopher M.: Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA : Springer-Verlag New York, Inc., 2006. – ISBN 0387310738

[3] CHEN, Zhe: Bayesian Filtering and From Kalman and Filters to and Particle Filters and Beyond, 2003

[4] ORCHARD, Marcos E.: A Particle Filtering-based Framework for On-line Fault Diagnosis and Failure Prognosis, Diss., 2006

[5] SIMON, D.: Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches. Wiley, 2006 https://books.google.de/books?id=UiMVoP_7TZkC. – ISBN 9780470045336
